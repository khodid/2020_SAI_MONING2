{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiTgeigdvP4QafiiAa6AKa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khodid/2020_SAI_MONING2/blob/master/lab07-2_Using_MNIST_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt6w53DPXgDP",
        "colab_type": "text"
      },
      "source": [
        "#MNIST Data set\n",
        "- 학습 내용\n",
        "  - MNIST Data Set이란 무엇인가?\n",
        "  - MNIST Classifier Code \n",
        "\n",
        "\n",
        "## MNIST Introduction\n",
        "\n",
        "[Wikipedia: MNIST Database](https://ko.wikipedia.org/wiki/MNIST_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4)\n",
        "\n",
        "[다운 받는 곳](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "\n",
        "- 개요:\n",
        "0-9까지의 숫자 이미지를 손글씨로 쓴 데이터로서, 손으로 쓴 우편번호를 인식하기 위해 마련된 데이터 세트다.\n",
        "\n",
        "- Train set : train-images-idx3-ubyte.gz / train-labels-idx1-ubyte.gz (6만장의 이미지와 label)\n",
        "- Test set : T10k-images-idx3-ubyte.gz / T10k-labels-idx1-ubyte.gz (만 장의 이미지와 label)\n",
        "\n",
        "이 마련되어 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNc91h9aaf0q",
        "colab_type": "text"
      },
      "source": [
        "## Example of MNIST\n",
        "\n",
        "- 28x28 image로 이루어짐.(748 pixel)\n",
        "- 1 channel of gray image\n",
        "- 0~9 digits\n",
        "\n",
        "실제론 이 28X28 이미지를 view라는 함수로 784개로 바꾸어 사용하게 만든다. \n",
        "\n",
        "``` python\n",
        "for X, Y in data_loader:\n",
        "  X = X.view(-1, 28*28)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcG90LyqcLyM",
        "colab_type": "text"
      },
      "source": [
        "### Torch Vision 패키지\n",
        "\n",
        "pytorch에서 불러올 수 있는 유명한 데이터 셋과 mosel architectures과 image transformation들을 담고 있다.\n",
        "\n",
        "[자세히 알고 싶으면 링크 참조](https://pytorch.org/docs/stable/torchvision/index.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2oTYFIfcIfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "3b049acd-f6fd-4bc7-c5af-bd689696c210"
      },
      "source": [
        "\n",
        "\n",
        "# 중략 ... \n",
        "\n",
        "mnist_train = dsets.MNIST(root=\"MNIST_data/\", train = True, transform = transforms.ToTensor(), download = True)\n",
        "# [ Parameter 설명 ]:\n",
        "# root      - MNIST data가 어느 경로에 있는지 설명 \n",
        "# train     - True로 할 시 MNIST의 Train set을 불러오고, False로 하면 Test set을 불러옴\n",
        "# transform - 이미지를 불러올 때 어떤 Transform으로 불러올 것인지. \n",
        "#             PyTorch의 경우 이미지는 0에서 1 사이의 값을 [Channel Highth Width] 의 형태로 갖는데, \n",
        "#             일반적인 Img 파일의 경우 0-255  사이 값을 [Highth Width Channel] 순서로 값을 갖는다 \n",
        "#             그래서 이미지의 순서와 값을 Pytorch에 맞게 바꿔 주는 게 ToTensor의 역할\n",
        "# download  - True로 할 시 Root에 MNIST Data가 존재하지 않으면 다운을 받겠다는 의미\n",
        "\n",
        "mnist_test = dsets.MNIST(root=\"MNIST_data/\", train = False, transform = transforms.ToTensor(), download = True)\n",
        "# test set도 마찬가지 함수로 다운 받아 준다.\n",
        "\n",
        "data_loader = torch.utils.DataLoader(DataLoader = mnist_train, batch_size = 100, shuffle = True, drop_last = True)\n",
        "\n",
        "# [ Parameter 설명 ]:\n",
        "# DataLoader - 어떤 데이터를 로드할 것인지\n",
        "# batch_size - 데이터를 불러올 때 몇 개씩 잘라서 불러올 것인지\n",
        "# shuffle    - True로 할 시 무작위로 섞어서 불러옴, False일 시 순서대로 불러옴\n",
        "# drop_last  - batch_size대로 잘라서 가져올 때, 남는 데이터는 어떻게 할지. True로 할 시 나머지 데이터는 사용X\n",
        "\n",
        "\n",
        "# ... 중략 ... \n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "  # ... 중략...\n",
        "  for X, Y in data_loader:\n",
        "      # data는 for문을 이용해서 불러옴.\n",
        "      # X에는 이미지, Y로는 label을.\n",
        "\n",
        "      X = X.view(-1, 28*28).to(device)\n",
        "      # 원래의 X는   [<batch_size>, 1_<channel>, 28_<highth>, 28_<width>] \n",
        "      # 바꾼 X는     [<batch_size>, 784]\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-65da484e40e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# test set도 마찬가지 함수로 다운 받아 준다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# [ Parameter 설명 ]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.utils' has no attribute 'DataLoader'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idOty7kSoP6y",
        "colab_type": "text"
      },
      "source": [
        "# Epoch, Batch size, Iteration\n",
        "\n",
        "머신러닝, 딥러닝, 등등의 분야에서 사용되는 개념이다.\n",
        "\n",
        "- Epoch: _training set 전체_가 학습에 한 번 사용이 되면 1 epoch이 돌았다고 부른다. \n",
        "- batch size: 한 epoch을 돌기 위해서 한꺼번에 테스트 데이터를 다 쓰면 너무 오래 걸림 - 그래서 잘라서 쓸 것. 자르는 묶음의 크기를 batch size라고 부르는 것. 6만장을 100개씩 자르면 600개의 batch를 얻게 될 것이다. \n",
        "- Iteration: batch를 몇 번 학습에 사용했느냐. (영어 원문: number of iterations means number of passes, each pass using \\[batch size\\] number of examples.\n",
        "\n",
        "\n",
        "예제 : 1000개의 Training Set을 갖고 있고, batch size를 500으로 할 것임. 그렇다면 1 epoch를 수행하기 위해 2 iterations가 필요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjQBsg8jqXAL",
        "colab_type": "text"
      },
      "source": [
        "### Softmax Classifier를 이용해 실습을 해보겠다..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YktF1EztlCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [ Data Load를 포함한 사전 세팅용 코드들... ]\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0C1sTrFqfdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "af044988-7df3-49de-a7e9-a79b0e5b88e5"
      },
      "source": [
        "\n",
        "# [ 여기부터가 강의에 나옴 ]\n",
        "\n",
        "linear = torch.nn.Linear(784, 10, bias = True).to(device)\n",
        "# input image는 784개 data, output은 0-9까지의 숫자. bias도 True로 둬서 같이 사용.\n",
        "\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)   # Softmax에 대해서 자동 계산해주는 함수가 있으므로 class 선언 필요 없음\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.1)\n",
        "\n",
        "## 위 까지가 기본적인 세팅\n",
        "\n",
        "# 15회 반복 (전체 데이터 훑기)\n",
        "for epoch in range(training_epochs):\n",
        "  avg_cost = 0\n",
        "  total_batch = len(data_loader)\n",
        "\n",
        "  # 1 epoch를 돌 때까지 반복\n",
        "  for X, Y in data_loader:\n",
        "    X = X.view(-1, 28*28).to(device)      # 아까 설명했듯 이미지 데이터 저장값 재조정하는 과정\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = linear(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    \n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    avg_cost += cost / total_batch\n",
        "    \n",
        "\n",
        "  print(\"E : \", \"%04d\" % (epoch+1), \"cost = \", \"{:.9f}\".format(avg_cost))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E :  0001 cost =  0.535468519\n",
            "E :  0002 cost =  0.359274149\n",
            "E :  0003 cost =  0.331187546\n",
            "E :  0004 cost =  0.316578060\n",
            "E :  0005 cost =  0.307158172\n",
            "E :  0006 cost =  0.300180733\n",
            "E :  0007 cost =  0.295130223\n",
            "E :  0008 cost =  0.290851504\n",
            "E :  0009 cost =  0.287417054\n",
            "E :  0010 cost =  0.284379601\n",
            "E :  0011 cost =  0.281825215\n",
            "E :  0012 cost =  0.279800683\n",
            "E :  0013 cost =  0.277808994\n",
            "E :  0014 cost =  0.276154310\n",
            "E :  0015 cost =  0.274440825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4gmhTzhulCi",
        "colab_type": "text"
      },
      "source": [
        "실제로 몇 만장의 데이터를 돌리니깐 한 epoch 지날 때마다 몇 초씩은 걸리는 걸 체감했다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHZ4MoeNuzr_",
        "colab_type": "text"
      },
      "source": [
        "### Test\n",
        "\n",
        "위에 학습한 모델을 테스트 세트를 로드해서 평가해보자.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRCNftRkvDX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "cc80df42-cf42-46e8-8b7d-3a7698712f98"
      },
      "source": [
        "with torch.no_grad():\n",
        "  # 이 범위 안에선 gradient를 계산하지 않겠다는 의미의 구문이다.\n",
        "  # Test를 할 때 이렇게 해둬야 한다고 한다. / 학습할까봐 그런 걸까?\n",
        "\n",
        "  X_test = mnist_test.test_data.view(-1, 28*28).float().to(device)\n",
        "  Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "  prediction = linear(X_test)\n",
        "  correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "  accuracy = correct_prediction.float().mean()\n",
        "  print(\"Accuracy\", accuracy.item())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8863000273704529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjSAymZKwJpc",
        "colab_type": "text"
      },
      "source": [
        "\\+ \\) matplotlib 라이브러리를 사용한다면 이 예측값과 test 이미지를 직접 시각적으로 확인할 수 있다."
      ]
    }
  ]
}
